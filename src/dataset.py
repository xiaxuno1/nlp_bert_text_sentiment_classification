#!/usr/bin/env python
# coding=utf-8
"""
@author: xiaxu
@license: MIT
@file: dataset.py
@date: 2025/11/10 16:33
@desc: 
"""
from datasets import load_from_disk
from torch.utils.data import DataLoader

from src import config


def get_dataloader(train=True):
    path = str(config.PROCESSED_DATA_DIR/ 'train' if train else 'test')
    dataset = load_from_disk(path)
    dataset.set_format('torch')
    return DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=True)

if __name__ == '__main__':
    train_dataloader = get_dataloader()
    test_dataloader = get_dataloader(train=False)
    print(len(train_dataloader))
    print(len(test_dataloader))

    for batch in train_dataloader:
        for k, v in batch.items():
            print(k,'->',v.shape)
        break